# ORAL (10 MIN)

## Introduction

Good Morning Everyone, what I'm going to talk about today is artificial intelligence. My presentation is divided in three parts, I'll start with a quick definition on what's an AI then I will look at how these AI can be useful for humankind so how they can help us in every day life next I'll take a look at what AI are bad at and why we shouldn't trust them and finally I'll make a quick conclusion.

## Definition

I believe that everyone here knows already what artificial intelligence means because it's one of the most hyped technology
of our century, and it represents 19% of companies pioneering.
But in case you don't know, it's just computers doing things that 
us as human can do but significantly faster. They can mimic, perform and improve.

Now that we've a definition in mind, you probably thinking 
" Well I already know what that meant, I've seen movies." Yes,
you've seen those movies like *Terminator* that portray AI as vilain that want to "destroy the human species". But reality, is much more fascinating and interesting than that. Like those two AI who have beaten champions at their game, I'm referring to *Alpha GO* and *Deep Blue*, the former is an AI who has beaten *Lee Sedol* at GO (Chinese abstract strategy game) and the ladder which is the most famous one, has beaten *Kasparov* at Chess. 
Or if you are more of a tech enthusiast, you know those voice assistants created by big companies like Google Home, Siri or Alexa, AI that can be quite useful and helpful. 

## How these AI can be useful for Humankind ?

In my opinion, AI was made in a goal of helping humans and make our life easier, and remove the everyday boring stuff.

During the Pandemic, many healthcare establishment decided to initiate the use of artificial intelligence in a way of helping,and
serves as an extension of the team, augmenting the capabilities of experts to be more efficient. The AI does not replace human expertise, as human feedback is a necessary part of the AI
relationship. So it's one of the examples of the growing relationship between AI and humans as a way of becoming more efficient and save much more lives.
A good example of this is the project *Neuralink* made by Elon Musk.
It's basically a chipset that will be surgically inserted into your brain so that he can analyze every brain cells and potentially save people with paralysis for example because it can make new neural connection to a bionic implant. It can also monitor our health.

AI can also be useful as a way to automate boring stuff as I said earlier, so for example in the harbours. In Rotterdam in the Netherlands, everything is autonomous. They are battery powered vehicules that are carrying and identifying containers then they will transport those containers from quayside to the container yard so that they can be deliver. They are still humans checking via cameras if everything is still working. 

AI can also be useful to make people more creative, and create much more innovative things. A good example of this is Holley Herndon, a musician and composer that made songs in collaboration with an AI called *Spawn* that she made with a team of engineers. So this AI try to recreate this abstract concept of what is music. So without any knowledge of what it is, the AI try to recreate notes, rythme, instruments. And it's quite interesting to heard his creation.

## Interruption 

To sum up what I just said, AI can be quite useful in everyday life,they can simplify, help and assists our life.

## What AI are bad at ? 

AI brain is mostly compare by scientists as an earthworm brain, so that means that they are quite stupid you might say. And yes, indeed their stupid but for a good reason. They don't know what it is to have a human point a view of things, they just achieve task via data given by their creators. 

To give you an example of that, a scientist called *Janelle Shane*, had the idea to ask an AI to made new ice cream flavour with a database of already existing flavour. So the AI try to create the next famous flavour. 
So here is the flavour that the AI came up with : Pumpkin Trash Break / Peanut Butter Slime / Strawberry Cream disease. This flavours doesn't seems very delicious, and this results was quite disappointing for Jannelle also. 

Many Scientists and well know people, like *Elon Musk* (CEO / Engineer) or *Stephen Hawking* (Scientist) have warned us about the potential danger AI can occure in the future. They can potentially become smarter than us even tho for know we don't need to worry about that. They can develop their own will and so destroy the human species and that is what we are the most scared of, because of the use of autonomous weapon in the US military for example.(Advanced Targeting and Lethality Automated System (ATLAS)). But I think we are the one who will choose what the AI for the future will be, we created it so we know what they can do.

## Conclusion 

To conclude, I will say that AI shows what humans are capable of creating, and I believe that this technology is the next big step of our evolution, the technology of tomorrow that will live in a relationship with us. And the future of AI is inspiring and promising for our next generation. Well that's it for me, Thank you for your attention and if you have any questions, I'll gladly answers them ! 



### Informations in case of 

#### History

Maturation of Artificial Intelligence (1943-1952)

    Year 1943: The first work which is now recognized as AI was done by Warren McCulloch and Walter pits in 1943. They proposed a model of artificial neurons.
    Year 1949: Donald Hebb demonstrated an updating rule for modifying the connection strength between neurons. His rule is now called Hebbian learning.
    Year 1950: The Alan Turing who was an English mathematician and pioneered Machine learning in 1950. Alan Turing publishes "Computing Machinery and Intelligence" in which he proposed a test. The test can check the machine's ability to exhibit intelligent behavior equivalent to human intelligence, called a Turing test.

The birth of Artificial Intelligence (1952-1956)

    Year 1955: An Allen Newell and Herbert A. Simon created the "first artificial intelligence program"Which was named as "Logic Theorist". This program had proved 38 of 52 Mathematics theorems, and find new and more elegant proofs for some theorems.
    Year 1956: The word "Artificial Intelligence" first adopted by American Computer scientist John McCarthy at the Dartmouth Conference. For the first time, AI coined as an academic field.

At that time high-level computer languages such as FORTRAN, LISP, or COBOL were invented. And the enthusiasm for AI was very high at that time.
The golden years-Early enthusiasm (1956-1974)

    Year 1966: The researchers emphasized developing algorithms which can solve mathematical problems. Joseph Weizenbaum created the first chatbot in 1966, which was named as ELIZA.
    Year 1972: The first intelligent humanoid robot was built in Japan which was named as WABOT-1.

The first AI winter (1974-1980)

    The duration between years 1974 to 1980 was the first AI winter duration. AI winter refers to the time period where computer scientist dealt with a severe shortage of funding from government for AI researches.
    During AI winters, an interest of publicity on artificial intelligence was decreased.

A boom of AI (1980-1987)

    Year 1980: After AI winter duration, AI came back with "Expert System". Expert systems were programmed that emulate the decision-making ability of a human expert.
    In the Year 1980, the first national conference of the American Association of Artificial Intelligence was held at Stanford University.

The second AI winter (1987-1993)

    The duration between the years 1987 to 1993 was the second AI Winter duration.
    Again Investors and government stopped in funding for AI research as due to high cost but not efficient result. The expert system such as XCON was very cost effective.

The emergence of intelligent agents (1993-2011)

    Year 1997: In the year 1997, IBM Deep Blue beats world chess champion, Gary Kasparov, and became the first computer to beat a world chess champion.
    Year 2002: for the first time, AI entered the home in the form of Roomba, a vacuum cleaner.
    Year 2006: AI came in the Business world till the year 2006. Companies like Facebook, Twitter, and Netflix also started using AI.

Deep learning, big data and artificial general intelligence (2011-present)

    Year 2011: In the year 2011, IBM's Watson won jeopardy, a quiz show, where it had to solve the complex questions as well as riddles. Watson had proved that it could understand natural language and can solve tricky questions quickly.
    Year 2012: Google has launched an Android app feature "Google now", which was able to provide information to the user as a prediction.
    Year 2014: In the year 2014, Chatbot "Eugene Goostman" won a competition in the infamous "Turing test."
    Year 2018: The "Project Debater" from IBM debated on complex topics with two master debaters and also performed extremely well.
    Google has demonstrated an AI program "Duplex" which was a virtual assistant and which had taken hairdresser appointment on call, and lady on other side didn't notice that she was talking with the machine.

Now AI has developed to a remarkable level. The concept of Deep learning, big data, and data science are now trending like a boom. Nowadays companies like Google, Facebook, IBM, and Amazon are working with AI and creating amazing devices. The future of Artificial Intelligence is inspiring and will come with high intelligence. 

#### Turing test

The Turing Test is a deceptively simple method of determining whether a machine can demonstrate human intelligence: If a machine can engage in a conversation with a human without being detected as a machine, it has demonstrated human intelligence.
The Turing Test was proposed in a paper published in 1950 by mathematician and computing pioneer Alan Turing. It has become a fundamental motivator in the theory and development of artificial Intelligence (AI). 

#### Three laws of robotics (Asimov's laws)

The best known set of laws are Isaac Asimov's "Three Laws of Robotics". These were introduced in his 1942 short story "Runaround", although they were foreshadowed in a few earlier stories. The Three Laws are:

    - A robot may not injure a human being or, through inaction, allow a human being to come to harm.
    - A robot must obey the orders given it by human beings except where such orders would conflict with the First Law.
    - A robot must protect its own existence as long as such protection does not conflict with the First or Second Laws.[1]

In The Evitable Conflict the machines generalize the First Law to mean:

    - "No machine may harm humanity; or, through inaction, allow humanity to come to harm."

This was refined in the end of Foundation and Earth, a zeroth law was introduced, with the original three suitably rewritten as subordinate to it:

   - A robot may not injure humanity, or, by inaction, allow humanity to come to harm.

#### EPSRC / AHRC principles of robotics

In 2011, the Engineering and Physical Sciences Research Council (EPSRC) and the Arts and Humanities Research Council (AHRC) of United Kingdom jointly published a set of five ethical "principles for designers, builders and users of robots" in the real world, along with seven "high-level messages" intended to be conveyed, based on a September 2010 research workshop:

    - Robots should not be designed solely or primarily to kill or harm humans.
    - Humans, not robots, are responsible agents. Robots are tools designed to achieve human goals.
    - Robots should be designed in ways that assure their safety and security.
    - Robots are artifacts; they should not be designed to exploit vulnerable users by evoking an emotional response or dependency. It should always be possible    to to tell a robot from a human.
    - It should always be possible to find out who is legally responsible for a robot.

The messages intended to be conveyed were:

    - We believe robots have the potential to provide immense positive impact to society. We want to encourage responsible robot research.
    - Bad practice hurts us all.
    - Addressing obvious public concerns will help us all make progress.
    - It is important to demonstrate that we, as roboticists, are committed to the best possible standards of practice.
    - To understand the context and consequences of our research, we should work with experts from other disciplines, including: social sciences, law, philosophy and the arts.
    - We should consider the ethics of transparency: are there limits to what should be openly available?
    When we see erroneous accounts in the press, we commit to take the time to contact the reporting journalists.

The EPSRC principles are broadly recognised as a useful starting point. In 2016 Tony Prescott organised a workshop to revise these principles, e.g. to differentiate ethical from legal principles.